\documentclass[english]{cgspaper} % change option to 'english' to include english logo in \copyrightspace

%\usepackage[ngerman]{babel} % comment out to use english in auto-generated section titles
\usepackage[utf8]{inputenc}
\usepackage[ruled]{algorithm}
\usepackage{algpseudocode}
\usepackage{url}
\usepackage{csquotes}

\title{Demonstration of Game-Based Object Detection}
\author{Tom Beckmann\\ Digital Engineering Faculty, Hasso Plattner Institute \textbar{} University of Potsdam}
\author{Philipp Bode\\ Digital Engineering Faculty, Hasso Plattner Institute \textbar{} University of Potsdam}
\author{Julius C. R. Rudolph\\ Digital Engineering Faculty, Hasso Plattner Institute \textbar{} University of Potsdam}
\author{Hendrik Rätz\\ Digital Engineering Faculty, Hasso Plattner Institute \textbar{} University of Potsdam}

% Konfiguration des Veranstaltungs-Feldes
\subject{%
    \textbf{Advanced Games of Life}\\
    Sommersemester 2018\\
    Themenstellung und Anleitung:
    Daniel Limberger und Prof.\ Dr.\ Jürgen Döllner}

\begin{document}

% Definition des Teasers
\teaser{
    \includegraphics[width=0.9\textwidth]{graphics/prozess.pdf}
    \caption{Beispiel für einen Teaser: Schritte beim Erstellen eines fachwissenschaftlichen Beitrags. Ein Teaser dient als Blickfang schon auf der ersten Seite eines Artikels.}
    \label{fig:prozess}
}

\maketitle

%----------------------------------------------------------------
% Zusammenfassung
%----------------------------------------------------------------
\begin{abstract}
\end{abstract}

\copyrightspace % Erzeugt den Hinweis auf die Veranstaltung links unten
\input{sections/introduction.tex}
\input{context.tex}

%----------------------------------------------------------------
% Related Work
%----------------------------------------------------------------
\section{Related Work}
\label{sec:related_work}
Related projects/Work

% Wie analysieren wir diese?
\input{sections/concept.tex}

%----------------------------------------------------------------
% Implementation
%----------------------------------------------------------------

% Implementierung des Spielkonzepts (vermutlich mit Fokus auf AR)
% Limitierungen von AR (bzw. Wie gehen wir damit um?)

\section{Gameplay Implementation}
\label{sec:gameplay_implementation}
% - game uses AR to capture demons; involves getting idea about the location, correlating it to 2D frames that are analyzed by pipeline
In this section, we will outline the implementation of Demon GO. We will first describe how the advanced game play elements for player vs player interactions are handled, then demonstrate how the augmented reality component allows players to capture demons, and then move on to the data exploitation subsystem. Snapshots from the augmented reality component form the bridge between the game and the exploitation subsystems. The exploitation subsystem consists of a light weight image processing pipeline on the player's phone and a server component for heavier processing.

\subsection{Map View}
- using MapBox to display an interactive map of the augmented world with markers at the positions of stashes (different colors for own and hostile stashes) with their perimeter/range of influence
- for own stashes the user also sees icons for every demon he placed to defend the stash 

- markers are pinned by geo-location on the map

\subsection{Storing and syncing stash data}
- need to easily sync the current game state (players, stashes, demons) across multiple clients on different devices

- using document-based NoSQL-database Google Firestore (cloud hosting, synced state across clients, easy setup) --> current flagship database of Google for mobile app development

- document hierarchy: player id --> stashes/null stash --> demons for stash (everything indexed by id)

- App implements change listeners for the collections of stashes and demons --> depending on what type of event happened stash/demon markers on the map (ideally only nearby) need to be redrawn
--> updated after every fight and every placement of a demon onto a stash

- demons that the player didn't place at a stash are saved in the player's "null-stash" which is not saved in the collection of stashes (as it does not need to be synced with the other players)
- updated when new demon was summoned or captured and after every fight in which the attacking demon lost health points

\subsection{Demon fights}

- the current implementation is a simulation that follows a round-based approach. In every round the attacking demon assaults one defending demon and afterwards gets assaulted by every defending demon sequentially. Thereby both the order in which the defenders are attacked by the attacker and the order in which the defenders counter-attack the attacking demon are shuffled once in advance of the fight. 

- makes the fight more unpredictable and harder for the attacker to guess which demons he might eliminate. After a fight both users are informed about the result (using Android Toast/Push Notification) and the health points of the surviving demons are updated in the corresponding Google Firestore documents.

- as users can currently add an unlimited amount of demons to a stash the defense of a stash gets exponentially stronger the more demons the defender places on them

- in a future version: defender can interactively intervene in the fight and dynamically add more defenders to the stash -> therefore fight must obviously take a while

\subsection{ARCore}
% - ARCore: definition, scope of the library, other applications (FIXME: move to a background section?)
ARCore is an augmented reality framework provided by Google. The project's roots began in a prototype framework called "Project Tango" in 2014 and had its first proper release in March 2018 \footnote{https://arstechnica.com/gadgets/2017/08/googles-arcore-brings-augmented-reality-to-millions-of-android-devices/}. ARCore is available on various platforms, including Android, iOS and the Unity Game Engine \footnote{https://developers.google.com/ar/discover/}.

% - Concepts: session w/ tracking info, anchors, plane detection --> focused on getting a stable "game board"
The core of ARCore is formed by a session which holds the features needed to track the movement of the user's phone as they move the device through three dimensional space. ARCore will continuously select tracking points based on the images from  the camera and compute the delta to points it found previously. Based on a set of these points, its main task is to detect and maintain stable planes that can act as a game board for virtual objects. It is then possible to register "anchors" with the session on the current location of any tracking point or any point on a detected plane. The position of these anchors will then be updated in the virtual space as ARCore's understanding of the real space changes. \footnote{https://developers.google.com/ar/discover/concepts}

% - our use: getting an idea about the room's dimensions, moving objects in virtual scene believably relative to phone's movement
For Demon GO, we aimed to have a virtual demon fly through the physical space the player is currently in. This had as a consequence that we had no use for ARCore's main feature of detecting planes, other than them being potential obstacles for collision detection. Instead, our use of ARCore served to get an estimate about the physical space's dimensions and having the demon move believably relative to the camera's movement.

% - estimating room size: incentivizing turning by defining a "start room" for demon that progressively grows --> assumes user is not pressed against a wall
To estimate the size of the physical space, we first define small "start room" of about 2 by 2 by 2 meters around the origin of the ARCore coordinate system, which corresponds to the location of the phone when the session was started, but moved to where ARCore believes the ground to be. The demon will move quickly to random points within this box, encouraging the player to turn to find the demon again. This way, we typically receive impressions in all four major directions of the physical space. ARCore will create tracking points as soon as the camera image changes and provide us with an estimate of their location in virtual space. We use these estimates to progressively grow the box the demon is allowed to use, such that, in the end, it will ideally be able to roam freely in a box-shaped estimate of the physical space. We limit the maximum extent of the space relative to the origin to keep the demon close by in open physical spaces.

% - problems w/ room size: abusing tracking points might include outliers that artificially extend the room --> makes game elements inaccessible; fast movement may reduce quality
Two issues arose from this approach: first, tracking points may include outliers that artificially extend the room size. This will have the most undesired consequence of game elements appearing to penetrate walls while providing x-ray vision to the user and put them effectively out of reach for any user interactions. Second, the fact that the demon moves quickly in small spaces initially not only encourages turning, but specifically may prompt players to turn quickly. The quick movement, however, reduces the quality of the camera images and makes it harder for ARCore to compute the delta movement, which in turn also reduces the quality of the understanding of the room's size as it is provided to us by ARCore.

\subsection{Snapshots}
% - every frame is distilled into a "Snapshot" containing pixel data, all tracking points, view-proj-matrices. pixel data is passed on to pipeline
We distill every frame provided by ARCore to a snapshot. This snapshot contains the pixel data, typically at a resolution of 1080 by 1920 pixels, the position in virtual space of all tracking points currently in the ARCore session and the current view and projection matrices of the virtual camera. These snapshots are pushed to a queue to which the pipeline of the exploitation subsystem, which runs in a separate thread, can pop from.

% - pipeline reports back with 2d PoI
% - challenge: likely won't have depth component for an arbitrary point on image
% - solution: project tracking points to 2d plane, find closest
When the pipeline has established what the points of interest in the picture of a snapshot are, if any, it will instruct the snapshot to map their two dimensional location on the picture back to a three dimensional point in the virtual game space. Due to the nature of the tracking points only appearing in "feature-rich" segments of the picture, we do not have a depth component for an arbitrary point on the image. However, most of the time, we will have multiple tracking points close by, as points of interest are often found in areas with a lot of "visual activity", that is, not just a white wall, but for example characters on a piece of paper or a brand logo. To solve the problem of lack of depth information, we make the assumption that any point that is as close as possible will suffice for our use case, since the 3D point is only used to direct our demon to the general area of the point of interest, in order to also lure the player to that same point. As such, we simply project all 3D tracking points onto the 2D plane of our picture using the camera view-projection matrix and select the corresponding 3D point of the closest point in 2D space as our point of interest in the virtual space.

% - pipeline calls project method, stores best hits for PoI
% - game/AR component later requests best 0-5 PoI from pipeline
% - generates random ones within room at reachable height to make game experience more consistent (i.e. not make game easier in plain rooms)
After projecting its 2D points of interest to 3D points, the pipeline will store these points along with a score. When the game informs the pipeline that the scanning phase is over and we need to move to the capturing phase, the pipeline will select those points with a highest score and provide them to the game subsystem. The game subsystem will then select between three and five points for the route of the demon during the capturing phase. If the pipeline provided too many points, those with a lower score will be discarded. If too little points were provided, the game subsystem will generate new points by randomly selecting a 3D point in the box that was previously established to be our physical space. This ensures that the game experience will appear coherent, independent of the output of the exploitation subsystem.

\section{Data Analysis Implementation}
\begin{figure*}
    \includegraphics[width=\textwidth]{graphics/pipeline_phase_1.png}
    \caption{Pipeline Phase 1}
    \label{fig:prozess}
\end{figure*}

% FIXME intro to OpenCV, features, usages?
- pipeline which processes every frame (captured by camera while capturing demons) on phone
- preselect frames which are sent to server
- only best should get sent
- pipeline consists of independent sets which could be ordered in any order -> same interface
- frames are wrapped in \textit{Snapshots} (ensures that the same object is passed between steps)

\subsection{Snapshots / Communication with Pipeline}
% FIXME in parts dupl with ARCore.Snapshots above -- might be fine if we focus on the pipeline-specific aspects
- holds OpenCV Mat (represents frame) and score (calculated in steps)
- also able to convert Mat to base64 and make a parameter list out of attributes (both for sending) 

- AR-Snapshots: additional fields (points in room and viewProjectionMatrix)

\subsection{Steps}
- contain list of following steps (in next)
- able to track time of execution
- .start(snap) -> .process(snap) -> .output(snap) (starts all steps in next with processed snapshots)

- special case: \textit{StepWithQueue}
- additional priority queue based on snapshot score
- getBestAndClear (angleChange) and getBest (sendingStep)
- used in angleChange and sendingStep where the only the best frame should be handled/should be handled first

% Daten-Analyse-Pipeline
 % Finden von PoI
 % Capturing und Processing
 
 \subsubsection{Blur Estimation}
 - try to use/analyze only those frames which are not too blurry and send those to the server (reduce traffic)
 - convert image to grayscale (only one channel)
 - apply Laplace Operator (edge detection)
 - calculate variance of it 
 -> used as score for blurriness: low value = high blurriness, high value = low blurriness
 - reason: Laplace detects edges, if edges are not to clear (low variance) picture may be blurry
 - transform blurriness value to value between 0 and 1 (everything above 500 is 1 everything else bluriness value/500)
\subsubsection{Brand/Pattern Recognition}
- Utilizes keypoint detection and feature descriptor matching to match recognizable patterns like brand logos and letterings \\
- The ORB (Oriented FAST and Rotated BRIEF) technique is used \cite{rublee2011orb} \\
- Computationally expensive step is keypoint calculation for frame.\\
-> Comparison with large number of patterns possible, as their keypoints can be precalculated.

\subsubsection{Contour Detection}
- Gaussian Blur -> bilateral filter -> Canny edge detection -> find Contours and cull by minimum size and maximal edges.\\
- Found contours are cropped and passed to next steps for likelihood of text estimation

\subsubsection{Noise Estimation}
- A simple kernel for fast noise estimation for which the authors note \enquote{In textured images or regions, though, the noise estimator perceives thin lines as noise.} \cite{immerkaer1996fast}. \\
- We utilize this property to detect probable regions with dense text.

\subsubsection{Colorfulness Estimation}
- Simple measure for estimating colorfulness of an image \cite{hasler2003measuring}. \\
- We presume that regions of legible text are usually low in color variance to increase the contrast between letters and background.

\subsection{Communication between phone and server}
- uses volley to send POST-requests to server
- adds best captured frame (out of Snapshot queue) to Volley-request-queue every 0.5s
- base64 encoded frame
- also adds a unique user ID and firebase token to request
- sending of requests in background asap

- every 100th frame is put directly into sending queue after going through blurriness and anglechange
- if no/few frames make it through the rest of the pipeline (contourdetction/noise) at least some frame frames are getting sent to server
- if over frames are in sending queue, frames with better scores are transmitted first


\subsection{Server-side Analysis}

- Flask/Flask-SocketIO server with sqllite db
- decodes received images and writes them to the disk (for now)
- detects where possible text is written on saved image
- crops image for every box \& saves it
- analyses rotaion of text, removes rotation and runs pytesseract on it 
- saves user\_id, filename of cropped img, analysed text, rotation, timestamp and confidence of analysis (given by pytesseract) to db
- also informs the frontend (?) about added and processed images via SocketIO


%----------------------------------------------------------------
% Evaluation
%----------------------------------------------------------------

\section{Evaluation}
\label{sec:evaluation}

% AR-Komponente (Bewegung des Dämons, Werden die PoI’s wiedergefunden, etc.)
% - biggest challenge: ensuring that tracking points at PoI remain consistent as user approaches; old visual context is lost as they focus e.g. on a single part of the desktop --> might cause ARCore to recalc coordinate system (could have been nice to pause allocation of tracking points and rely on accelerometer, but ARCore does not support this)
\subsection{Tracking point accuracy}
The most important limitation for the augmented reality subsystem we encountered was the stability of tracking points in the virtual space. As described before, quick movement caused ARCore to lose track of many of the points and creating new ones, thus invalidating potentially crucial information about the room. Since the setting of the game encourages of feeling of hunting after the demon, quick movements are unfortunately an expected and potentially necessary part of the game. Further problems arose when the user moved closer towards a point of interest at which the demon was sitting. As they approach the point, a lot of points all around the room will "disappear" as the frame of the camera narrows in on the area of interest. This would not necessarily be a problem, however ARCore will constantly recompute the coordinate system and make considerable corrections to the origin when it loses important tracking information or gets a lot of new points in an area. Often, this had the effect of the demon getting farther and farther away from the player as they approach it, even though it appeared to be sitting at a constant position.

At the time of writing, ARCore does not expose an option to "freeze" the coordinate system. This functionality would have likely remedied our issues, if we froze the coordinate system when switching to the capturing phase, where stable positions are essential, and relied on the phone's accelerometer and picture data to move the camera in the existing virtual space. ARCore did not expose sufficient access to the lower level system for us to try this approach by ourselves, so we will either have to wait for its developers to add this functionality or use and modify an open source augmented reality framework to solve this specific use case.

% FIXME: to be tested further:
% - by defining anchors on the relevant tracking points, ARCore will ensure most of the time that objects remain within reach -- timeout and fallback to showing spell even though user is not close enough otherwise
As a workaround to this issue, we make use of the ARCore anchors, which will update and move around the coordinate system to try and make up for changes to the coordinate system's origin or scale. This helped most of the time to ensure that the demon will at least be within the activation distance for the capturing phase, but it still appeared to coast around the spot. To not block the game altogether when the demon "hides" in a wall, we added a timeout that will move the game onwards in the hope that the next point may be better.

\subsection{Demon movement}
% - movement of demon feels weird at start, as dimensions of room are unknown
The movement of the demon in our current implementation is simplistic and makes next to no use of advanced possibilities, like collision detection. This is mainly because the quality of the tracking points even for our room size estimation may vary greatly, so that we chose to use the simplest possible primitive volume in 3D space to reduce the chance of the demon getting locked within non-existing obstacles that have been formed by errors in the tracking point estimation.

% - placement of waypoints close to user confuse, but as they traverse the room and turn frequently it's hard to predict where they will be
Our concept of exploring the room size by encouraging the user to turn frequently at the start of the session, by making the room very small, may lead to some confusion as the demon appears to travel through impossible ways, for example through the user.As the room quickly grows bigger, this may not be as much of an issue, however it may make sense to add a better waypoint system than simply selecting random points in the known space. This may also help to make the demon feel like a more believable creature.

\subsection{User experience}
% FIXME: to be evaluated if that applies to anyone else but me:
- handling of phone is tricky: most users held phone in right hand, shot w/ left hand in scanning phase. switch hands when entering capturing phase for drawing spells --> messes up coordinate system as phone points to floor temporarily

% Erkennung der Points of Interest
- Blurriness: Laplacian is not too precise, e.g. when using shallow focus, some regions are completely focused whereas some are totally blurry
--> will result in low blurriness value

% Brand-Detection

% Textanalyse mit OCR
- Wo wird im Bild Text erkannt?
- Kann dieser Text interpretiert werden, wenn ja, wie gut?
- Was sind Probleme? (Schriftart, Blurriness, distortion)

% Scalability

%----------------------------------------------------------------
% Conclusion
%----------------------------------------------------------------
\section{Conclusion}
\label{sec:conclusion}

% Future Work
- z.B. weitere Daten sammeln und komplexere Nutzerprofile anlegen
- Data Analytics auf den gesammelten Infos

%----------------------------------------------------------------
% Sources
%----------------------------------------------------------------
\bibliographystyle{acmsiggraph}
\bibliography{foo-paper}

\end{document}
